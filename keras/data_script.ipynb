{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets81_train.txt', 'r') as f:\n",
    "    datasets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_id.txt', 'r') as f:\n",
    "    label = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_id(sep = ' ', file_path = 'word_id.txt'):\n",
    "    \"\"\"读取标签文件\n",
    "    # Args\n",
    "        file_path: 标签文件格式为`word sep label`\n",
    "    # Returns\n",
    "        A dict format of {label:index}\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        word_dict = {}\n",
    "        for line in f.readlines():\n",
    "            words = line.split(sep)\n",
    "            label = words[1].strip()\n",
    "            index = int(words[0].strip())\n",
    "            word_dict[label] = index\n",
    "    return word_dict\n",
    "word_index = read_word_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actor\\\\0013_1106962433.jpg*': [24], 'actor\\\\0018_470960261.jpg*': [15], 'actor\\\\0031_2406153318.jpg*': [0, 3], 'actor\\\\0033_213660760.jpg*': [28], 'actor\\\\0034_569936943.jpg*': [4], 'actor\\\\0041_2456602544.jpg*': [31, 23, 24], 'actor\\\\0049_2163720456.jpg*': [24], 'actor\\\\0064_2343195092.jpg*': [38], 'actor\\\\0081_2159186964.jpg*': [23], 'actor\\\\0211_2233188435.jpg*': [22, 30], 'actor\\\\0213_1850366878.jpg*': [21, 44], 'actor\\\\0219_453334665.jpg*': [6], 'actor\\\\0224_954526140.jpg*': [24], 'actor\\\\0229_433478352.jpg*': [23, 21, 44], 'actor\\\\0231_637866194.jpg*': [6, 43], 'actor\\\\0258_1053942091.jpg*': [22], 'actor\\\\0273_2727864150.jpg*': [24], 'actor\\\\0279_2321264821.jpg*': [32, 18], 'actor\\\\0284_2060799990.jpg*': [46], 'actor\\\\0333_82685319.jpg*': [24], 'actor\\\\0378_344147378.jpg*': [32], 'actor\\\\0393_173349342.jpg*': [36], 'actor\\\\0435_522150101.jpg*': [34, 8], 'actor\\\\0438_2504620853.jpg*': [24], 'actor\\\\0448_2291046386.jpg*': [23], 'actor\\\\0463_2483322510.jpg*': [1, 23], 'actor\\\\0485_292906123.jpg*': [31, 26], 'actor\\\\0491_335496963.jpg*': [9, 31, 24, 5, 41], 'actor\\\\0495_870673543.jpg*': [46], 'actor\\\\0530_2568827539.jpg*': [29]}\n"
     ]
    }
   ],
   "source": [
    "def read_image_tag(sep=' ', file_path='datasets81_train.txt'):\n",
    "    \"\"\"读取图片对应的标签\n",
    "    # Args\n",
    "        file_path:\n",
    "    # Returns\n",
    "        A dict format of {img:tags}\n",
    "    \"\"\"\n",
    "    word_index = read_word_id()\n",
    "    with open(file_path, 'r') as f:\n",
    "        word_dict = {}\n",
    "        for line in f.readlines():\n",
    "            words = line.split(sep)\n",
    "            img = words[0].strip()\n",
    "            tags = [word_index[words[x].strip()] for x in range(1,len(words))]\n",
    "            word_dict[img] = tags\n",
    "    return word_dict\n",
    "print(read_image_tag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "def to_catagorical(labels):\n",
    "    word_dict = {}\n",
    "    length = len(labels)\n",
    "    s = set(labels)\n",
    "    tags_num = len(s)\n",
    "    for i in range(len(s)):\n",
    "        word_dict[labels[i]] = i\n",
    "    catagorical = np.zeros(shape=(length,tags_num))\n",
    "    return word_dict\n",
    "print(to_catagorical([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
